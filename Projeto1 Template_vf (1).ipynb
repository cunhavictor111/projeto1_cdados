{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Lara Christine Melo Vasconcelos\n",
    "\n",
    "Nome: João Lucas Brasileiro\n",
    "\n",
    "Nome: Laisa Camilly \n",
    "\n",
    "Nome: Victor de Almeida Cunha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de até 4 pessoas, mas com uma rubrica mais exigente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\Victor Cunha\\Desktop\\Atividades\\C-Dados\\CDADOS - DP\\projeto1_cdados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com as mensagens dos seus arquivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>NPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denver to Orlando. I made a mistake when prep...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On January 8 2015 I had the displeasure of bei...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noumea to Napier via Auckland. Paid an extra...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San Francisco to Phuket via Guangzhou on 22n...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I checked our family of 6 in online before we ...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review        NPS\n",
       "0   Denver to Orlando. I made a mistake when prep...   Promoter\n",
       "1  On January 8 2015 I had the displeasure of bei...  Detractor\n",
       "2    Noumea to Napier via Auckland. Paid an extra...  Detractor\n",
       "3    San Francisco to Phuket via Guangzhou on 22n...  Detractor\n",
       "4  I checked our family of 6 in online before we ...  Detractor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dados_treino_QUARTETO_Victor de Almeida Cunha.csv')\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>NPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In general good service, but we don't have muc...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta will always be my first choice across th...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can confirm what has been reported earlier a...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As a long time Continental customer and I real...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I flew Air India from Newark to Mumbai and b...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review        NPS\n",
       "0  In general good service, but we don't have muc...    Passive\n",
       "1  Delta will always be my first choice across th...   Promoter\n",
       "2  I can confirm what has been reported earlier a...  Detractor\n",
       "3  As a long time Continental customer and I real...    Passive\n",
       "4    I flew Air India from Newark to Mumbai and b...    Passive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = pd.read_csv('dados_teste_QUARTETO_Victor de Almeida Cunha.csv')\n",
    "teste.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o contexto referente aos rótulos cujas mensagens (ou reviews) deverão ser classificadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensinamos o classificador utilizando como conceito principal a ingenuidade (probabilidade utilizando Naive-Bayes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(Palavra|Promoter) = \\frac{P(Promoter|Palavra) P(Palavra)}{P(Promoter)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(Palavra|Promoter) = \\frac{P(Promoter|Palavra) P(Palavra)}{P(Promoter)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(Palavra|Detractor) = \\frac{P(Detractor|Palavra) P(Palavra)}{P(Detractor)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para iniciar o projeto, realizamos a limpeza dos dados, removendo caracteres especiais e stop words. Isso nos ajudará pois fará com que as palavras e sinais especiais não interfiram nos resultados finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando caracteres especiais\n",
    "def limpar(texto):\n",
    "    especial = '\"\\'(),:.$.!?-#'\n",
    "    limpo = ''\n",
    "    for caracter in texto:\n",
    "        if caracter not in especial:\n",
    "            limpo += caracter\n",
    "    limpo = limpo.lower().encode(\"ascii\", \"ignore\")\n",
    "    limpo  = limpo.decode()\n",
    "\n",
    "#Limpando stop words\n",
    "    stopwords = [\"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"ain't\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"aren't\", \"arise\", \"around\", \"as\", \"a's\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"can't\", \"cause\", \"causes\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"c'mon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"couldnt\", \"couldn't\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"c's\", \"ct\", \"cu\", \"currently\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"didn't\", \"different\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"done\", \"don't\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"empty\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \"h3\", \"had\", \"hadn\", \"hadn't\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"hed\", \"he'd\", \"he'll\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"here's\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"he's\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\", \"home\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"how's\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"i'd\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"i'll\", \"im\", \"i'm\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"invention\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"it\", \"itd\", \"it'd\", \"it'll\", \"its\", \"it's\", \"itself\", \"iv\", \"i've\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"let's\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mightn't\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needn\", \"needn't\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\", \"otherwise\", \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shan't\", \"she\", \"shed\", \"she'd\", \"she'll\", \"shes\", \"she's\", \"should\", \"shouldn\", \"shouldn't\", \"should've\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"thats\", \"that's\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"there's\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'd\", \"they'll\", \"theyre\", \"they're\", \"they've\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"t's\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"ut\", \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\", \"wasn\", \"wasnt\", \"wasn't\", \"way\", \"we\", \"wed\", \"we'd\", \"welcome\", \"well\", \"we'll\", \"well-b\", \"went\", \"were\", \"we're\", \"weren\", \"werent\", \"weren't\", \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"what's\", \"when\", \"whence\", \"whenever\", \"when's\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"where's\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whom\", \"whomever\", \"whos\", \"who's\", \"whose\", \"why\", \"why's\", \"wi\", \"widely\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"won't\", \"words\", \"world\", \"would\", \"wouldn\", \"wouldnt\", \"wouldn't\", \"www\", \"x\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"you'd\", \"you'll\", \"your\", \"youre\", \"you're\", \"yours\", \"yourself\", \"yourselves\", \"you've\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\"]\n",
    "    limpo = limpo.split()\n",
    "    no_stop = ''\n",
    "    for word in limpo:\n",
    "        if word not in stopwords:\n",
    "            no_stop += word + \" \"\n",
    "    \n",
    "    return no_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As três classificações do projeto ('Passive', 'Promoter' e 'Detractor') foram separadas e para cada uma foi elaborada uma lista contendo as palavras pertinentes à sua categoria. \n",
    "Após isso, criou-se suas respectivas Series, e, por último, uma Series com a frequência relativa de cada palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar string contendo todas as palavras do passive\n",
    "todas_palavras_passive = train.loc[train.NPS == 'Passive', 'Review']\n",
    "todas_palavras_passive = limpar((todas_palavras_passive).to_string(index = False)).split() #index = False remove o indice da Series\n",
    "\n",
    "#Criando uma series \n",
    "serie_passive = pd.Series(todas_palavras_passive)\n",
    "\n",
    "#Criando series comm frequencia relativa de cada palavra\n",
    "tabela_passive_relativa = serie_passive.value_counts(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar string contendo todas as palavras do promoter\n",
    "todas_palavras_promoter = train.loc[train.NPS == 'Promoter', 'Review']\n",
    "todas_palavras_promoter = limpar((todas_palavras_promoter).to_string(index = False)).split() #index = False remove o indice da Series\n",
    "\n",
    "#Criando uma series \n",
    "serie_promoter = pd.Series(todas_palavras_promoter)\n",
    "\n",
    "#Criando series com frequencia relativa de cada palavra\n",
    "tabela_promoter_relativa = serie_promoter.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar string contendo todas as palavras do detractor\n",
    "todas_palavras_detractor = train.loc[train.NPS == 'Detractor', 'Review']\n",
    "todas_palavras_detractor = limpar((todas_palavras_detractor).to_string(index = False)).split() #index = False remove o indice da Series\n",
    "\n",
    "#Criando uma series \n",
    "serie_detractor = pd.Series(todas_palavras_detractor)\n",
    "\n",
    "#Criando series com frequencia relativa de cada palavra\n",
    "tabela_detractor_relativa = serie_detractor.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criado um conjunto de palavras que engloba todas as palavras presentes em todos as categorias. Elas foram transformadas em uma Series e, posteriormente, foi criado uma outra Series com a frequência relativa de cada palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todas as palavras\n",
    "todas_palavras = todas_palavras_passive + todas_palavras_detractor + todas_palavras_promoter\n",
    "\n",
    "#Criando uma series\n",
    "serie_todas_palavras = pd.Series(todas_palavras)\n",
    "\n",
    "#frequencia relativa de cada palavra, do conjunto todas as palavras\n",
    "tabela_todas_palavras_relativa = serie_todas_palavras.value_counts(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi gerado a probabilidade de cada uma das categorias acontecer, de acordo com o conjunto de palavras dos dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_detractor = train.NPS.value_counts(True)[0]\n",
    "prob_passive = train.NPS.value_counts(True)[2]\n",
    "prob_promoter = train.NPS.value_counts(True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criado um classificador, o qual recebe a frase a ser classificada, limpa essa frase, e gera as probabilidades da frase dado a categoria, sendo retornado a probabilidade da categoria dado a frase. Vale salientar que foi realizado uma suavização de Laplace, a qual melhora a precisão para palavras com pouca ocorrência. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador(phrase) -> str:\n",
    "    phrase = limpar(phrase)\n",
    "    frase = phrase.split()\n",
    "\n",
    "    detractor = 1\n",
    "    passive = 1\n",
    "    promoter = 1\n",
    "\n",
    "    for word in frase:\n",
    "        if word in todas_palavras_detractor:\n",
    "            detractor *= (tabela_detractor_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "        else: \n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            detractor *= 1 / (tabela_detractor_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "\n",
    "        if word in todas_palavras_passive:\n",
    "            passive *= (tabela_passive_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "        else:\n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            passive *= 1 / (tabela_passive_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "            \n",
    "        if word in todas_palavras_promoter:\n",
    "            promoter *= (tabela_promoter_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "        else:\n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            promoter *= 1 / (tabela_promoter_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "\n",
    "    detractor *= prob_detractor\n",
    "    passive *= prob_passive\n",
    "    promoter *= prob_promoter\n",
    "\n",
    "    p = {\"Detractor\" : detractor, \"Passive\" : passive, \"Promoter\" : promoter}\n",
    "\n",
    "    return max(p,key=p.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, os dados do dataframe de treino foi comparado com  os dados classificados dela função Classificador, possibilitando saber qual a precisão do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Detractor</th>\n",
       "      <th>Passive</th>\n",
       "      <th>Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detractor</th>\n",
       "      <td>39.666667</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>6.976190</td>\n",
       "      <td>5.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter</th>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.642857</td>\n",
       "      <td>29.119048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      Detractor   Passive   Promoter\n",
       "NPS                                      \n",
       "Detractor  39.666667  2.857143   4.500000\n",
       "Passive     3.333333  6.976190   5.761905\n",
       "Promoter    4.142857  3.642857  29.119048"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_train = []\n",
    "for frase in train[\"Review\"]:\n",
    "    auto_train.append(Classificador(frase))\n",
    "\n",
    "pd.crosstab(train.NPS,auto_train,normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precisão do classificador automático pode ser medida por somar as porcentagens diagonais (ou seja, Detractor com Detractor + Promoter com Promoter + Passive com Passive). \n",
    "\n",
    "Portanto, a precisão do classificador com a base de treino é de aproximadamente 75,74%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Uma dedução inicial traçada é que, como os bancos de dados de treino e teste são diferentes, é natural que a base de testes seja levemente menos precisa que a de treino, dado que há a possibilidade de haver novas palavras, probabilidades diferentes, etc.\n",
    "\n",
    "Repetindo o mesmo processo para saber a performance do classificador com o banco de treino, utilizaremos agora o banco de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Detractor</th>\n",
       "      <th>Passive</th>\n",
       "      <th>Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detractor</th>\n",
       "      <td>39.277778</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>5.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>3.888889</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>7.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter</th>\n",
       "      <td>4.722222</td>\n",
       "      <td>6.388889</td>\n",
       "      <td>26.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      Detractor   Passive   Promoter\n",
       "NPS                                      \n",
       "Detractor  39.277778  3.222222   5.055556\n",
       "Passive     3.888889  3.500000   7.555556\n",
       "Promoter    4.722222  6.388889  26.388889"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_test = []\n",
    "for frase in teste[\"Review\"]:\n",
    "\n",
    "    # Nesse loop, estamos considerando todas as probabilidades traçadas antes, mas na base de dados de teste.\n",
    "\n",
    "    auto_test.append(Classificador(frase))\n",
    "\n",
    "pd.crosstab(teste.NPS,auto_test,normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetindo o mesmo processo para saber a precisão, temos aproximadamente 66,15% na base de testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando a base de testes como a necessária, é possível dizer que o classificador é razoavelmente preciso. Mas por que há uma discrepância relativamente alta entre as precisões nas diferentes bases de dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dito antes, as probabilidades em cada base de dados é diferente. Se uma palavra tem, de acordo com a base de treino, uma chance de 50% de aparecer em um determinado tipo de frase, ela pode ter uma chance de 25% no mesmo tipo de frase na base de teste. \n",
    "\n",
    "Essa é uma lógica inicial que explica uma discrepância qualquer entre as bases de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frases de diferentes tamanhos também interferem na precisão geral do classificador. Se existe uma frase que apenas diz \"foi ruim\", é mais fácil de saber que foi negativa do que uma frase mais elaborada com a mesma avaliação.\n",
    "\n",
    "Essa é uma outra explicação pelo qual o classificador não alcançou uma precisão maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, ele seria inadequado para poder ser aplicado com eficiência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas como poderíamos melhorar o classificador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Melhorias ao Classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma maneira de melhorar o classificador seria de considerar sequências de palavras. O intuito dessa solução seria de minimizar o fator humano de ironias, que é uma das características das avaliações que mais prejudica o classificador. Essa solução poderia ser implementada com contadores de quantas palavras de cada tipo que há e comparar com a probabilidade final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma outra maneira poderia ser de considerar diferentes frases dentro da própria avaliação. Essa solução seria eficaz ao aplicar ao classificador um contador de quantas frases de cada tipo há na avaliação e comparar com o cálculo probabilístico já aplicado antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "### Podemos criar novas avaliações com o classificador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo se as melhorias fossem aplicadas e o classificador provasse ser eficaz, ele não seria capaz de escrever uma nova avaliação. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não da maneira que está sendo implementado, pelo menos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que o classificador pudesse criar novas avaliações, ele deveria passar não apenas por uma refatoração radical, mas também um treinamento muito extenso de linguagem, muito parecido com os treinamentos de IAs como ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o intuito que foi criado e da maneira que funciona, nosso classificador iria, no melhor dos casos, criar uma avaliação com palavras soltas e uma pontuação inconsistente, por mais que fosse possível compreender a avaliação dada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tentar implementar uma das soluções propostas na seção de melhorias: o contador de palavras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, vamos mudar algumas coisas no classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador(phrase) -> str:\n",
    "    phrase = limpar(phrase)\n",
    "    frase = phrase.split()\n",
    "\n",
    "    # Vamos contar quantas palavras há de cada tipo e o total de palavras na frase.\n",
    "\n",
    "    words_detractor = 0\n",
    "    words_passive = 0\n",
    "    words_promoter = 0\n",
    "    words_total = 0\n",
    "\n",
    "    detractor = 1\n",
    "    passive = 1\n",
    "    promoter = 1\n",
    "\n",
    "    for word in frase:\n",
    "        if word in todas_palavras_detractor:\n",
    "            detractor *= (tabela_detractor_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "            words_detractor += 1\n",
    "        else: \n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            detractor *= 1 / (tabela_detractor_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "\n",
    "        if word in todas_palavras_passive:\n",
    "            passive *= (tabela_passive_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "            words_passive += 1\n",
    "        else:\n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            passive *= 1 / (tabela_passive_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "            \n",
    "        if word in todas_palavras_promoter:\n",
    "            promoter *= (tabela_promoter_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "            words_promoter += 1\n",
    "        else:\n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            promoter *= 1 / (tabela_promoter_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "        words_total += 1\n",
    "\n",
    "    detractor *= prob_detractor\n",
    "    passive *= prob_passive\n",
    "    promoter *= prob_promoter\n",
    "\n",
    "    p = {\"Detractor\" : detractor, \"Passive\" : passive, \"Promoter\" : promoter}\n",
    "    word_prob = {\"Detractor\": words_detractor,\"Passive\": words_passive,\"Promoter\": words_promoter}\n",
    "\n",
    "    # O segundo dicionário mostra quantas palavras existem de cada tipo na frase. \n",
    "    # Nessa implementação, uma mesma palavra pode ser de dois tipos.\n",
    "\n",
    "    review = max(p,key=p.get)\n",
    "    p_max = max(p.values())\n",
    "    word_max = max(word_prob,key=word_prob.get)\n",
    "    word_max_prob = word_prob[word_max]/words_total\n",
    "\n",
    "    if p_max == word_max:\n",
    "        return review\n",
    "    elif word_max_prob > p_max:\n",
    "        return word_max\n",
    "    elif word_max_prob < p_max:\n",
    "        return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima, estamos considerando a probabilidade condicional e a probabilidade dadas quantas palavras há de cada tipo. Porém, uma palavra **pode ser de mais de um tipo** para a segunda probabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Detractor</th>\n",
       "      <th>Passive</th>\n",
       "      <th>Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detractor</th>\n",
       "      <td>44.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>5.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter</th>\n",
       "      <td>16.055556</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>18.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      Detractor   Passive   Promoter\n",
       "NPS                                      \n",
       "Detractor  44.166667  0.500000   2.888889\n",
       "Passive     9.333333  0.555556   5.055556\n",
       "Promoter   16.055556  2.666667  18.777778"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_test = []\n",
    "for frase in teste[\"Review\"]:\n",
    "\n",
    "    # Nesse loop, estamos considerando todas as probabilidades traçadas antes, mas na base de dados de teste.\n",
    "\n",
    "    auto_test.append(Classificador(frase))\n",
    "\n",
    "pd.crosstab(teste.NPS,auto_test,normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precisão ficou parecida, mas vamos considerar casos em que uma palavra pode ser de **apenas um tipo**, utilizando a probabilidade dessa palavra em cada tipo como comparador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classificador(phrase) -> str:\n",
    "    phrase = limpar(phrase)\n",
    "    frase = phrase.split()\n",
    "\n",
    "    # Vamos contar quantas palavras há de cada tipo e o total de palavras na frase.\n",
    "\n",
    "    words_detractor = 0\n",
    "    words_passive = 0\n",
    "    words_promoter = 0\n",
    "    words_total = 0\n",
    "\n",
    "    detractor = 1\n",
    "    passive = 1\n",
    "    promoter = 1\n",
    "\n",
    "    for word in frase:\n",
    "\n",
    "        prob_word = {}\n",
    "\n",
    "        if word in todas_palavras_detractor:\n",
    "            detractor *= (tabela_detractor_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "            prob_word[\"Detractor\"] = tabela_detractor_relativa[word]\n",
    "        else: \n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            detractor *= 1 / (tabela_detractor_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "\n",
    "        if word in todas_palavras_passive:\n",
    "            passive *= (tabela_passive_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "            prob_word[\"Passive\"] = tabela_passive_relativa[word]\n",
    "        else:\n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            passive *= 1 / (tabela_passive_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "            \n",
    "        if word in todas_palavras_promoter:\n",
    "            promoter *= (tabela_promoter_relativa[word])/tabela_todas_palavras_relativa[word]\n",
    "            prob_word[\"Promoter\"] = tabela_promoter_relativa[word]\n",
    "        else:\n",
    "            #Foi realizado uma suavização de Laplace, considerando que a palavra não aparece, a formula seria: 0 + 1 / (total de palavras da categoria + total de palavras)\n",
    "            promoter *= 1 / (tabela_promoter_relativa.sum() + tabela_todas_palavras_relativa.sum())\n",
    "        words_total += 1\n",
    "\n",
    "        if len(prob_word) != 0:\n",
    "            prob_word = max(prob_word,key=prob_word.get)\n",
    "            if prob_word == \"Detractor\":\n",
    "                words_detractor += 1\n",
    "            if prob_word == \"Passive\":\n",
    "                words_passive += 1\n",
    "            if prob_word == \"Promoter\":\n",
    "                words_promoter += 1\n",
    "\n",
    "    detractor *= prob_detractor\n",
    "    passive *= prob_passive\n",
    "    promoter *= prob_promoter\n",
    "\n",
    "    p = {\"Detractor\" : detractor, \"Passive\" : passive, \"Promoter\" : promoter}\n",
    "    word_prob = {\"Detractor\": words_detractor,\"Passive\": words_passive,\"Promoter\": words_promoter}\n",
    "\n",
    "    # O segundo dicionário mostra quantas palavras existem de cada tipo na frase. \n",
    "    # Nessa implementação, uma mesma palavra pode ser de apenas um tipo.\n",
    "\n",
    "    review = max(p,key=p.get)\n",
    "    p_max = max(p.values())\n",
    "    word_max = max(word_prob,key=word_prob.get)\n",
    "    word_max_prob = word_prob[word_max]/words_total\n",
    "\n",
    "    if p_max == word_max:\n",
    "        return review\n",
    "    elif word_max_prob > p_max:\n",
    "        return word_max\n",
    "    elif word_max_prob < p_max:\n",
    "        return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Detractor</th>\n",
       "      <th>Passive</th>\n",
       "      <th>Promoter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detractor</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Passive</th>\n",
       "      <td>6.666667</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>3.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter</th>\n",
       "      <td>10.944444</td>\n",
       "      <td>10.444444</td>\n",
       "      <td>16.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      Detractor    Passive   Promoter\n",
       "NPS                                       \n",
       "Detractor  42.000000   3.666667   1.888889\n",
       "Passive     6.666667   4.444444   3.833333\n",
       "Promoter   10.944444  10.444444  16.111111"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_test = []\n",
    "for frase in teste[\"Review\"]:\n",
    "\n",
    "    # Nesse loop, estamos considerando todas as probabilidades traçadas antes, mas na base de dados de teste.\n",
    "\n",
    "    auto_test.append(Classificador(frase))\n",
    "\n",
    "pd.crosstab(teste.NPS,auto_test,normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando apenas um tipo, o classificador foi levemente menos impreciso do que o de dois tipos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, é possível traçar duas conclusões sobre essa solução: ela é ineficaz em melhorar o classificador ou deve ser implementada juntamente com outra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas mensagens. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU arquivo com três categorias na classificação das variáveis (OBRIGATÓRIO PARA QUARTETOS, sem contar como item avançado)\n",
    "* CONSTRUIU o cálculo das probabilidades corretamente utilizando bigramas E apresentou referência sobre o método utilizado.\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários diferentes, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
